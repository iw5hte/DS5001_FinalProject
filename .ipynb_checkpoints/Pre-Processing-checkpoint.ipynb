{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841d1125",
   "metadata": {},
   "source": [
    "# Pre-Processing Plato's Dialogues\n",
    "## Iris Wu (iw5hte@virginia.edu) DS 5001 Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934e824",
   "metadata": {},
   "source": [
    "## End goal of this notebook:\n",
    "Convert the collection from their source formats (F0) into a set of tables that conform to the Standard Text Analytic Data Model (F2) and Annotate these tables with statistical and linguistic features using NLP libraries such as NLTK (F3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86ec1c",
   "metadata": {},
   "source": [
    "### Setting up necessary tools:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a5119",
   "metadata": {},
   "source": [
    "Importing useful packages -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0d62a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly.express as px\n",
    "from textparser import TextParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc60d7",
   "metadata": {},
   "source": [
    "Defining useful filepaths for reading and outputting data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e077532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = f'data'\n",
    "out_path = f'data/output/plato'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766e7dd",
   "metadata": {},
   "source": [
    "Defining useful lists and patterns corresponding to each document for later preprocessing -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5129a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c2c24",
   "metadata": {},
   "source": [
    "ohco_pat_list refers to the chapter pattern delineations. Some of Plato's dialogues remain undivided, or at least undivided in any sensible fashion, so they remain one big chunk of texts. Others, like The Republic, are divided into books. beginning_pat is a dictionary used to eliminate Benjamin Jowett's superfluous commentary and introductions to the dialogues in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "af83ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "\n",
    "ohco_pat_list = [\n",
    "    \n",
    "    (1676,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1677,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1600,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1656, rf\"APOLOGY\"),\n",
    "    (1580,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1616,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1571,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1657,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1681,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1598,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1642,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1672,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1635,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1584,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1673,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1682,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1579,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1643,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1687,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1658,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1636,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1744,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1591,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1735,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1738,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1726,   rf\"PERSONS OF THE DIALOGUE:\"),\n",
    "    (1572,   rf\"^Section\\s+\\d+.$\"),\n",
    "    (1497,  rf\"^\\s*BOOK\\s+{roman}\\.\\s*$\"),\n",
    "    (1750,  rf\"^\\s*BOOK\\s+{roman}\\.\\s*$\")\n",
    "    \n",
    "]\n",
    "\n",
    "beginning_pat = {\n",
    "    1571 : [\"sense of the artistic difficulty of the design, cannot be determined.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1572 : [\"or anticipates the discoveries of modern science.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1580 : [\"rather to belong to a later stage of the philosophy of Plato.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1676 : [\"(see Appendix I above)\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1616 : [\"to the latter work the author of this Essay is largely indebted\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1677 : [\"century before Christ.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1656 : [\"the eyes of the Athenian public.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1681 : [\"an imitator of Plato.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1598 : [\"assigning to the Euthydemus any other position in the series.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1642 : [\"trial or the reverse, can any evidence of the date be obtained.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1672 : [\"daily life are not overlooked.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1635 : [\"this truly Platonic little work is not a forgery of later times.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1584 : [\"could not have been a young man at any time after the battle of Delium.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1673 : [\"sufficient reasons for doubting the genuineness of the work.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1579 : [\"Friendship; Cic. de Amicitia.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1682 : [\"Platonic writings.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1643 : [\"another.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1750 : [\"THE PREAMBLE.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1591 : [\"elements of human nature are reconciled.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1687 : [\"but deeply rooted in history and in the human\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1636 : [\"the fear that literature will ever die out.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1658 : [\"linger among critical uncertainties.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1744 : [\"'spectator of all time and of all existence'?\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1735 : [\"'fragments of the great banquet' of Hegel.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1738 : [\"be reunited with the great body of the Platonic writings.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1600 : [\"together in a series the memorials of the life of Socrates.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1497 : [\"introduced in the Timaeus.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1726 : [\"opportunity of learning.\", r\"\\*\\*\\*\\s*END OF\"],\n",
    "    1657 : [\"occur in Plato.\", r\"End of this Project Gutenberg Etext of Crito, by Plato\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775e75d",
   "metadata": {},
   "source": [
    "Functions to be used in processing - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc5a08",
   "metadata": {},
   "source": [
    "The below function is used to tokenize a document. This is drawn from Professor Alvarado's function in module 4 with a few modifications and his textparser.py class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "43e96db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_collection(LIB, clip_pats):\n",
    "\n",
    "    books = []\n",
    "    for book_id in LIB.index:\n",
    "\n",
    "        # Announce\n",
    "        print(\"Tokenizing\", book_id, LIB.loc[book_id].raw_title)\n",
    "\n",
    "        # Define vars\n",
    "        chap_regex = LIB.loc[book_id].chap_regex\n",
    "        ohco_pats = [('chap', chap_regex, 'm')]\n",
    "        src_file_path = LIB.loc[book_id].source_file_path\n",
    "\n",
    "        # Create object\n",
    "        text = TextParser(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats[book_id], use_nltk=True)\n",
    "\n",
    "        # Define parameters\n",
    "        text.verbose = True\n",
    "        text.strip_hyphens = True\n",
    "        text.strip_whitespace = True\n",
    "\n",
    "        # Parse\n",
    "        text.import_source().parse_tokens()\n",
    "\n",
    "        # Name things\n",
    "        text.TOKENS['book_id'] = book_id\n",
    "        text.TOKENS = text.TOKENS.reset_index().set_index(['book_id'] + text.OHCO)\n",
    "\n",
    "        # Add to list\n",
    "        books.append(text.TOKENS)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    CORPUS = pd.concat(books).sort_index()\n",
    "\n",
    "    # Clean up\n",
    "    del(books)\n",
    "    del(text)\n",
    "        \n",
    "    print(\"Done\")\n",
    "        \n",
    "    return CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d31bc9",
   "metadata": {},
   "source": [
    "The below function is used to gather a table of tokens into a document table of varying OHCO levels (as defined in the OHCO list above). This function also draws on Professor Alvarado's Module 4 code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b2589899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather(TOKENS, ohco_level):\n",
    "    level_name = OHCO[ohco_level-1].split('_')[0]\n",
    "    df = TOKENS.reset_index().groupby(OHCO[:ohco_level])\\\n",
    "        .token_str.apply(lambda x: x.str.cat(sep=' '))\\\n",
    "        .to_frame(f\"{level_name}_str\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1afb8",
   "metadata": {},
   "source": [
    "Importing the data and creating the LIB table -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "55366b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ALCIBIADES_I-pg1676.txt',\n",
       " 'data/ALCIBIADES_II-pg1677.txt',\n",
       " 'data/APOLOGY-pg1656.txt',\n",
       " 'data/CHARMIDES-pg1580.txt',\n",
       " 'data/CRATYLUS-pg1616.txt',\n",
       " 'data/CRITIAS-pg1571.txt',\n",
       " 'data/CRITO-pg1657.txt',\n",
       " 'data/ERYXIAS-pg1681.txt',\n",
       " 'data/EUTHYDEMUS-pg1598.txt',\n",
       " 'data/EUTHYPHRO-pg1642.txt',\n",
       " 'data/GORGIAS-pg1672.txt',\n",
       " 'data/ION-pg1635.txt',\n",
       " 'data/LACHES-pg1584.txt',\n",
       " 'data/LAWS-pg1750.txt',\n",
       " 'data/LESSER_HIPPIAS-pg1673.txt',\n",
       " 'data/LYSIS-pg1579.txt',\n",
       " 'data/MENEXENUS-pg1682.txt',\n",
       " 'data/MENO-pg1643.txt',\n",
       " 'data/PARMENIDES-pg1687.txt',\n",
       " 'data/PHAEDO-pg1658.txt',\n",
       " 'data/PHAEDRUS-pg1636.txt',\n",
       " 'data/PHILEBUS-pg1744.txt',\n",
       " 'data/PROTAGORAS-pg1591.txt',\n",
       " 'data/SOPHIST-pg1735.txt',\n",
       " 'data/STATESMAN-pg1738.txt',\n",
       " 'data/SYMPOSIUM-pg1600.txt',\n",
       " 'data/THEAETETUS-pg1726.txt',\n",
       " 'data/THE_REPUBLIC-pg1497.txt',\n",
       " 'data/TIMAEUS-pg1572.txt']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_list = sorted(glob(f\"{source_files}/*.*\"))\n",
    "source_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5e3e7b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>data/THE_REPUBLIC-pg1497.txt</td>\n",
       "      <td>THE REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>data/CRITIAS-pg1571.txt</td>\n",
       "      <td>CRITIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>data/TIMAEUS-pg1572.txt</td>\n",
       "      <td>TIMAEUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>data/LYSIS-pg1579.txt</td>\n",
       "      <td>LYSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>data/CHARMIDES-pg1580.txt</td>\n",
       "      <td>CHARMIDES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>data/LACHES-pg1584.txt</td>\n",
       "      <td>LACHES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>data/PROTAGORAS-pg1591.txt</td>\n",
       "      <td>PROTAGORAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>data/EUTHYDEMUS-pg1598.txt</td>\n",
       "      <td>EUTHYDEMUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>data/SYMPOSIUM-pg1600.txt</td>\n",
       "      <td>SYMPOSIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>data/CRATYLUS-pg1616.txt</td>\n",
       "      <td>CRATYLUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>data/ION-pg1635.txt</td>\n",
       "      <td>ION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>data/PHAEDRUS-pg1636.txt</td>\n",
       "      <td>PHAEDRUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>data/EUTHYPHRO-pg1642.txt</td>\n",
       "      <td>EUTHYPHRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>data/MENO-pg1643.txt</td>\n",
       "      <td>MENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>data/APOLOGY-pg1656.txt</td>\n",
       "      <td>APOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>data/CRITO-pg1657.txt</td>\n",
       "      <td>CRITO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>data/PHAEDO-pg1658.txt</td>\n",
       "      <td>PHAEDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>data/GORGIAS-pg1672.txt</td>\n",
       "      <td>GORGIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>data/LESSER_HIPPIAS-pg1673.txt</td>\n",
       "      <td>LESSER HIPPIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>data/ALCIBIADES_I-pg1676.txt</td>\n",
       "      <td>ALCIBIADES I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>data/ALCIBIADES_II-pg1677.txt</td>\n",
       "      <td>ALCIBIADES II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>data/ERYXIAS-pg1681.txt</td>\n",
       "      <td>ERYXIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>data/MENEXENUS-pg1682.txt</td>\n",
       "      <td>MENEXENUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>data/PARMENIDES-pg1687.txt</td>\n",
       "      <td>PARMENIDES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>data/THEAETETUS-pg1726.txt</td>\n",
       "      <td>THEAETETUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>data/SOPHIST-pg1735.txt</td>\n",
       "      <td>SOPHIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>data/STATESMAN-pg1738.txt</td>\n",
       "      <td>STATESMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>data/PHILEBUS-pg1744.txt</td>\n",
       "      <td>PHILEBUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>data/LAWS-pg1750.txt</td>\n",
       "      <td>LAWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_file_path       raw_title\n",
       "book_id                                                \n",
       "1497       data/THE_REPUBLIC-pg1497.txt    THE REPUBLIC\n",
       "1571            data/CRITIAS-pg1571.txt         CRITIAS\n",
       "1572            data/TIMAEUS-pg1572.txt         TIMAEUS\n",
       "1579              data/LYSIS-pg1579.txt           LYSIS\n",
       "1580          data/CHARMIDES-pg1580.txt       CHARMIDES\n",
       "1584             data/LACHES-pg1584.txt          LACHES\n",
       "1591         data/PROTAGORAS-pg1591.txt      PROTAGORAS\n",
       "1598         data/EUTHYDEMUS-pg1598.txt      EUTHYDEMUS\n",
       "1600          data/SYMPOSIUM-pg1600.txt       SYMPOSIUM\n",
       "1616           data/CRATYLUS-pg1616.txt        CRATYLUS\n",
       "1635                data/ION-pg1635.txt             ION\n",
       "1636           data/PHAEDRUS-pg1636.txt        PHAEDRUS\n",
       "1642          data/EUTHYPHRO-pg1642.txt       EUTHYPHRO\n",
       "1643               data/MENO-pg1643.txt            MENO\n",
       "1656            data/APOLOGY-pg1656.txt         APOLOGY\n",
       "1657              data/CRITO-pg1657.txt           CRITO\n",
       "1658             data/PHAEDO-pg1658.txt          PHAEDO\n",
       "1672            data/GORGIAS-pg1672.txt         GORGIAS\n",
       "1673     data/LESSER_HIPPIAS-pg1673.txt  LESSER HIPPIAS\n",
       "1676       data/ALCIBIADES_I-pg1676.txt    ALCIBIADES I\n",
       "1677      data/ALCIBIADES_II-pg1677.txt   ALCIBIADES II\n",
       "1681            data/ERYXIAS-pg1681.txt         ERYXIAS\n",
       "1682          data/MENEXENUS-pg1682.txt       MENEXENUS\n",
       "1687         data/PARMENIDES-pg1687.txt      PARMENIDES\n",
       "1726         data/THEAETETUS-pg1726.txt      THEAETETUS\n",
       "1735            data/SOPHIST-pg1735.txt         SOPHIST\n",
       "1738          data/STATESMAN-pg1738.txt       STATESMAN\n",
       "1744           data/PHILEBUS-pg1744.txt        PHILEBUS\n",
       "1750               data/LAWS-pg1750.txt            LAWS"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_data = []\n",
    "for source_file_path in source_file_list:\n",
    "    book_id = int(source_file_path.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "    book_title = source_file_path.split('/')[-1].split('-')[0].replace('_', ' ')\n",
    "    book_data.append((book_id, source_file_path, book_title))\n",
    "LIB = pd.DataFrame(book_data, columns=['book_id','source_file_path','raw_title'])\\\n",
    "    .set_index('book_id').sort_index()\n",
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9d0d207e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "      <th>chap_regex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>data/THE_REPUBLIC-pg1497.txt</td>\n",
       "      <td>THE REPUBLIC</td>\n",
       "      <td>^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>data/CRITIAS-pg1571.txt</td>\n",
       "      <td>CRITIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>data/TIMAEUS-pg1572.txt</td>\n",
       "      <td>TIMAEUS</td>\n",
       "      <td>^Section\\s+\\d+.$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>data/LYSIS-pg1579.txt</td>\n",
       "      <td>LYSIS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>data/CHARMIDES-pg1580.txt</td>\n",
       "      <td>CHARMIDES</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>data/LACHES-pg1584.txt</td>\n",
       "      <td>LACHES</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>data/PROTAGORAS-pg1591.txt</td>\n",
       "      <td>PROTAGORAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>data/EUTHYDEMUS-pg1598.txt</td>\n",
       "      <td>EUTHYDEMUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>data/SYMPOSIUM-pg1600.txt</td>\n",
       "      <td>SYMPOSIUM</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>data/CRATYLUS-pg1616.txt</td>\n",
       "      <td>CRATYLUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>data/ION-pg1635.txt</td>\n",
       "      <td>ION</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>data/PHAEDRUS-pg1636.txt</td>\n",
       "      <td>PHAEDRUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>data/EUTHYPHRO-pg1642.txt</td>\n",
       "      <td>EUTHYPHRO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>data/MENO-pg1643.txt</td>\n",
       "      <td>MENO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>data/APOLOGY-pg1656.txt</td>\n",
       "      <td>APOLOGY</td>\n",
       "      <td>APOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>data/CRITO-pg1657.txt</td>\n",
       "      <td>CRITO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>data/PHAEDO-pg1658.txt</td>\n",
       "      <td>PHAEDO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>data/GORGIAS-pg1672.txt</td>\n",
       "      <td>GORGIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>data/LESSER_HIPPIAS-pg1673.txt</td>\n",
       "      <td>LESSER HIPPIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>data/ALCIBIADES_I-pg1676.txt</td>\n",
       "      <td>ALCIBIADES I</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>data/ALCIBIADES_II-pg1677.txt</td>\n",
       "      <td>ALCIBIADES II</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>data/ERYXIAS-pg1681.txt</td>\n",
       "      <td>ERYXIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>data/MENEXENUS-pg1682.txt</td>\n",
       "      <td>MENEXENUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>data/PARMENIDES-pg1687.txt</td>\n",
       "      <td>PARMENIDES</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>data/THEAETETUS-pg1726.txt</td>\n",
       "      <td>THEAETETUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>data/SOPHIST-pg1735.txt</td>\n",
       "      <td>SOPHIST</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>data/STATESMAN-pg1738.txt</td>\n",
       "      <td>STATESMAN</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>data/PHILEBUS-pg1744.txt</td>\n",
       "      <td>PHILEBUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>data/LAWS-pg1750.txt</td>\n",
       "      <td>LAWS</td>\n",
       "      <td>^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_file_path       raw_title  \\\n",
       "book_id                                                   \n",
       "1497       data/THE_REPUBLIC-pg1497.txt    THE REPUBLIC   \n",
       "1571            data/CRITIAS-pg1571.txt         CRITIAS   \n",
       "1572            data/TIMAEUS-pg1572.txt         TIMAEUS   \n",
       "1579              data/LYSIS-pg1579.txt           LYSIS   \n",
       "1580          data/CHARMIDES-pg1580.txt       CHARMIDES   \n",
       "1584             data/LACHES-pg1584.txt          LACHES   \n",
       "1591         data/PROTAGORAS-pg1591.txt      PROTAGORAS   \n",
       "1598         data/EUTHYDEMUS-pg1598.txt      EUTHYDEMUS   \n",
       "1600          data/SYMPOSIUM-pg1600.txt       SYMPOSIUM   \n",
       "1616           data/CRATYLUS-pg1616.txt        CRATYLUS   \n",
       "1635                data/ION-pg1635.txt             ION   \n",
       "1636           data/PHAEDRUS-pg1636.txt        PHAEDRUS   \n",
       "1642          data/EUTHYPHRO-pg1642.txt       EUTHYPHRO   \n",
       "1643               data/MENO-pg1643.txt            MENO   \n",
       "1656            data/APOLOGY-pg1656.txt         APOLOGY   \n",
       "1657              data/CRITO-pg1657.txt           CRITO   \n",
       "1658             data/PHAEDO-pg1658.txt          PHAEDO   \n",
       "1672            data/GORGIAS-pg1672.txt         GORGIAS   \n",
       "1673     data/LESSER_HIPPIAS-pg1673.txt  LESSER HIPPIAS   \n",
       "1676       data/ALCIBIADES_I-pg1676.txt    ALCIBIADES I   \n",
       "1677      data/ALCIBIADES_II-pg1677.txt   ALCIBIADES II   \n",
       "1681            data/ERYXIAS-pg1681.txt         ERYXIAS   \n",
       "1682          data/MENEXENUS-pg1682.txt       MENEXENUS   \n",
       "1687         data/PARMENIDES-pg1687.txt      PARMENIDES   \n",
       "1726         data/THEAETETUS-pg1726.txt      THEAETETUS   \n",
       "1735            data/SOPHIST-pg1735.txt         SOPHIST   \n",
       "1738          data/STATESMAN-pg1738.txt       STATESMAN   \n",
       "1744           data/PHILEBUS-pg1744.txt        PHILEBUS   \n",
       "1750               data/LAWS-pg1750.txt            LAWS   \n",
       "\n",
       "                         chap_regex  \n",
       "book_id                              \n",
       "1497     ^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$  \n",
       "1571       PERSONS OF THE DIALOGUE:  \n",
       "1572               ^Section\\s+\\d+.$  \n",
       "1579       PERSONS OF THE DIALOGUE:  \n",
       "1580       PERSONS OF THE DIALOGUE:  \n",
       "1584       PERSONS OF THE DIALOGUE:  \n",
       "1591       PERSONS OF THE DIALOGUE:  \n",
       "1598       PERSONS OF THE DIALOGUE:  \n",
       "1600       PERSONS OF THE DIALOGUE:  \n",
       "1616       PERSONS OF THE DIALOGUE:  \n",
       "1635       PERSONS OF THE DIALOGUE:  \n",
       "1636       PERSONS OF THE DIALOGUE:  \n",
       "1642       PERSONS OF THE DIALOGUE:  \n",
       "1643       PERSONS OF THE DIALOGUE:  \n",
       "1656                        APOLOGY  \n",
       "1657       PERSONS OF THE DIALOGUE:  \n",
       "1658       PERSONS OF THE DIALOGUE:  \n",
       "1672       PERSONS OF THE DIALOGUE:  \n",
       "1673       PERSONS OF THE DIALOGUE:  \n",
       "1676       PERSONS OF THE DIALOGUE:  \n",
       "1677       PERSONS OF THE DIALOGUE:  \n",
       "1681       PERSONS OF THE DIALOGUE:  \n",
       "1682       PERSONS OF THE DIALOGUE:  \n",
       "1687       PERSONS OF THE DIALOGUE:  \n",
       "1726       PERSONS OF THE DIALOGUE:  \n",
       "1735       PERSONS OF THE DIALOGUE:  \n",
       "1738       PERSONS OF THE DIALOGUE:  \n",
       "1744       PERSONS OF THE DIALOGUE:  \n",
       "1750     ^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB['chap_regex'] = LIB.index.map(pd.Series({x[0]:x[1] for x in ohco_pat_list}))\n",
    "LIB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e2c62",
   "metadata": {},
   "source": [
    "Applying the tokenize_collection function to make the token table -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e10fa355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 1497 THE REPUBLIC\n",
      "Importing  data/THE_REPUBLIC-pg1497.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1571 CRITIAS\n",
      "Importing  data/CRITIAS-pg1571.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1572 TIMAEUS\n",
      "Importing  data/TIMAEUS-pg1572.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^Section\\s+\\d+.$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1579 LYSIS\n",
      "Importing  data/LYSIS-pg1579.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1580 CHARMIDES\n",
      "Importing  data/CHARMIDES-pg1580.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1584 LACHES\n",
      "Importing  data/LACHES-pg1584.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1591 PROTAGORAS\n",
      "Importing  data/PROTAGORAS-pg1591.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1598 EUTHYDEMUS\n",
      "Importing  data/EUTHYDEMUS-pg1598.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1600 SYMPOSIUM\n",
      "Importing  data/SYMPOSIUM-pg1600.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1616 CRATYLUS\n",
      "Importing  data/CRATYLUS-pg1616.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1635 ION\n",
      "Importing  data/ION-pg1635.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1636 PHAEDRUS\n",
      "Importing  data/PHAEDRUS-pg1636.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1642 EUTHYPHRO\n",
      "Importing  data/EUTHYPHRO-pg1642.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1643 MENO\n",
      "Importing  data/MENO-pg1643.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1656 APOLOGY\n",
      "Importing  data/APOLOGY-pg1656.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone APOLOGY\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1657 CRITO\n",
      "Importing  data/CRITO-pg1657.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1658 PHAEDO\n",
      "Importing  data/PHAEDO-pg1658.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1672 GORGIAS\n",
      "Importing  data/GORGIAS-pg1672.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1673 LESSER HIPPIAS\n",
      "Importing  data/LESSER_HIPPIAS-pg1673.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1676 ALCIBIADES I\n",
      "Importing  data/ALCIBIADES_I-pg1676.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwu/Documents/School/Undergrad/Third Year/Spring 2023/DS 5001/Final Project/textparser.py:99: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  start = self.LINES.line_str.str.contains(start_pat, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1677 ALCIBIADES II\n",
      "Importing  data/ALCIBIADES_II-pg1677.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1681 ERYXIAS\n",
      "Importing  data/ERYXIAS-pg1681.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1682 MENEXENUS\n",
      "Importing  data/MENEXENUS-pg1682.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1687 PARMENIDES\n",
      "Importing  data/PARMENIDES-pg1687.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1726 THEAETETUS\n",
      "Importing  data/THEAETETUS-pg1726.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1735 SOPHIST\n",
      "Importing  data/SOPHIST-pg1735.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1738 STATESMAN\n",
      "Importing  data/STATESMAN-pg1738.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1744 PHILEBUS\n",
      "Importing  data/PHILEBUS-pg1744.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone PERSONS OF THE DIALOGUE:\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1750 LAWS\n",
      "Importing  data/LAWS-pg1750.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1497</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(I, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(went, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>went</td>\n",
       "      <td>went</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(down, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(yesterday, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(to, TO)</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1750</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">127</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>(EBook, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>EBook</td>\n",
       "      <td>ebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(of, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Laws,, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Laws,</td>\n",
       "      <td>laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(by, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Plato, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738994 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos  token_str  \\\n",
       "book_id chap_id para_num sent_num token_num                                    \n",
       "1497    1       1        0        0                 (I, PRP)  PRP          I   \n",
       "                                  1              (went, VBD)  VBD       went   \n",
       "                                  2               (down, RB)   RB       down   \n",
       "                                  3          (yesterday, NN)   NN  yesterday   \n",
       "                                  4                 (to, TO)   TO         to   \n",
       "...                                                      ...  ...        ...   \n",
       "1750    12      127      0        5             (EBook, NNP)  NNP      EBook   \n",
       "                                  6                 (of, IN)   IN         of   \n",
       "                                  7             (Laws,, NNP)  NNP      Laws,   \n",
       "                                  8                 (by, IN)   IN         by   \n",
       "                                  9             (Plato, NNP)  NNP      Plato   \n",
       "\n",
       "                                              term_str  \n",
       "book_id chap_id para_num sent_num token_num             \n",
       "1497    1       1        0        0                  i  \n",
       "                                  1               went  \n",
       "                                  2               down  \n",
       "                                  3          yesterday  \n",
       "                                  4                 to  \n",
       "...                                                ...  \n",
       "1750    12      127      0        5              ebook  \n",
       "                                  6                 of  \n",
       "                                  7               laws  \n",
       "                                  8                 by  \n",
       "                                  9              plato  \n",
       "\n",
       "[738994 rows x 4 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS = tokenize_collection(LIB, beginning_pat)\n",
    "CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb97826",
   "metadata": {},
   "source": [
    "Adding more metadata to the LIB table, such as book length and the number of chapters -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4c48b9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>book_len</th>\n",
       "      <th>n_chaps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>data/THE_REPUBLIC-pg1497.txt</td>\n",
       "      <td>THE REPUBLIC</td>\n",
       "      <td>^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "      <td>118510</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>data/CRITIAS-pg1571.txt</td>\n",
       "      <td>CRITIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>6792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>data/TIMAEUS-pg1572.txt</td>\n",
       "      <td>TIMAEUS</td>\n",
       "      <td>^Section\\s+\\d+.$</td>\n",
       "      <td>69918</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>data/LYSIS-pg1579.txt</td>\n",
       "      <td>LYSIS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>9188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>data/CHARMIDES-pg1580.txt</td>\n",
       "      <td>CHARMIDES</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>10751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>data/LACHES-pg1584.txt</td>\n",
       "      <td>LACHES</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>10286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>data/PROTAGORAS-pg1591.txt</td>\n",
       "      <td>PROTAGORAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>22998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>data/EUTHYDEMUS-pg1598.txt</td>\n",
       "      <td>EUTHYDEMUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>15882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>data/SYMPOSIUM-pg1600.txt</td>\n",
       "      <td>SYMPOSIUM</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>22251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>data/CRATYLUS-pg1616.txt</td>\n",
       "      <td>CRATYLUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>23939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>data/ION-pg1635.txt</td>\n",
       "      <td>ION</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>5178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>data/PHAEDRUS-pg1636.txt</td>\n",
       "      <td>PHAEDRUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>23210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>data/EUTHYPHRO-pg1642.txt</td>\n",
       "      <td>EUTHYPHRO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>6793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>data/MENO-pg1643.txt</td>\n",
       "      <td>MENO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>12855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>data/APOLOGY-pg1656.txt</td>\n",
       "      <td>APOLOGY</td>\n",
       "      <td>APOLOGY</td>\n",
       "      <td>11406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>data/CRITO-pg1657.txt</td>\n",
       "      <td>CRITO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>5389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>data/PHAEDO-pg1658.txt</td>\n",
       "      <td>PHAEDO</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>27512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>data/GORGIAS-pg1672.txt</td>\n",
       "      <td>GORGIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>35833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>data/LESSER_HIPPIAS-pg1673.txt</td>\n",
       "      <td>LESSER HIPPIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>6048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>data/ALCIBIADES_I-pg1676.txt</td>\n",
       "      <td>ALCIBIADES I</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>14811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>data/ALCIBIADES_II-pg1677.txt</td>\n",
       "      <td>ALCIBIADES II</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>5531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>data/ERYXIAS-pg1681.txt</td>\n",
       "      <td>ERYXIAS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>6419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>data/MENEXENUS-pg1682.txt</td>\n",
       "      <td>MENEXENUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>6581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>data/PARMENIDES-pg1687.txt</td>\n",
       "      <td>PARMENIDES</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>18974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>data/THEAETETUS-pg1726.txt</td>\n",
       "      <td>THEAETETUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>31453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>data/SOPHIST-pg1735.txt</td>\n",
       "      <td>SOPHIST</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>22230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>data/STATESMAN-pg1738.txt</td>\n",
       "      <td>STATESMAN</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>23617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>data/PHILEBUS-pg1744.txt</td>\n",
       "      <td>PHILEBUS</td>\n",
       "      <td>PERSONS OF THE DIALOGUE:</td>\n",
       "      <td>23398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>data/LAWS-pg1750.txt</td>\n",
       "      <td>LAWS</td>\n",
       "      <td>^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "      <td>141143</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_file_path       raw_title  \\\n",
       "book_id                                                   \n",
       "1497       data/THE_REPUBLIC-pg1497.txt    THE REPUBLIC   \n",
       "1571            data/CRITIAS-pg1571.txt         CRITIAS   \n",
       "1572            data/TIMAEUS-pg1572.txt         TIMAEUS   \n",
       "1579              data/LYSIS-pg1579.txt           LYSIS   \n",
       "1580          data/CHARMIDES-pg1580.txt       CHARMIDES   \n",
       "1584             data/LACHES-pg1584.txt          LACHES   \n",
       "1591         data/PROTAGORAS-pg1591.txt      PROTAGORAS   \n",
       "1598         data/EUTHYDEMUS-pg1598.txt      EUTHYDEMUS   \n",
       "1600          data/SYMPOSIUM-pg1600.txt       SYMPOSIUM   \n",
       "1616           data/CRATYLUS-pg1616.txt        CRATYLUS   \n",
       "1635                data/ION-pg1635.txt             ION   \n",
       "1636           data/PHAEDRUS-pg1636.txt        PHAEDRUS   \n",
       "1642          data/EUTHYPHRO-pg1642.txt       EUTHYPHRO   \n",
       "1643               data/MENO-pg1643.txt            MENO   \n",
       "1656            data/APOLOGY-pg1656.txt         APOLOGY   \n",
       "1657              data/CRITO-pg1657.txt           CRITO   \n",
       "1658             data/PHAEDO-pg1658.txt          PHAEDO   \n",
       "1672            data/GORGIAS-pg1672.txt         GORGIAS   \n",
       "1673     data/LESSER_HIPPIAS-pg1673.txt  LESSER HIPPIAS   \n",
       "1676       data/ALCIBIADES_I-pg1676.txt    ALCIBIADES I   \n",
       "1677      data/ALCIBIADES_II-pg1677.txt   ALCIBIADES II   \n",
       "1681            data/ERYXIAS-pg1681.txt         ERYXIAS   \n",
       "1682          data/MENEXENUS-pg1682.txt       MENEXENUS   \n",
       "1687         data/PARMENIDES-pg1687.txt      PARMENIDES   \n",
       "1726         data/THEAETETUS-pg1726.txt      THEAETETUS   \n",
       "1735            data/SOPHIST-pg1735.txt         SOPHIST   \n",
       "1738          data/STATESMAN-pg1738.txt       STATESMAN   \n",
       "1744           data/PHILEBUS-pg1744.txt        PHILEBUS   \n",
       "1750               data/LAWS-pg1750.txt            LAWS   \n",
       "\n",
       "                         chap_regex  book_len  n_chaps  \n",
       "book_id                                                 \n",
       "1497     ^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$    118510       10  \n",
       "1571       PERSONS OF THE DIALOGUE:      6792        1  \n",
       "1572               ^Section\\s+\\d+.$     69918        8  \n",
       "1579       PERSONS OF THE DIALOGUE:      9188        1  \n",
       "1580       PERSONS OF THE DIALOGUE:     10751        1  \n",
       "1584       PERSONS OF THE DIALOGUE:     10286        1  \n",
       "1591       PERSONS OF THE DIALOGUE:     22998        1  \n",
       "1598       PERSONS OF THE DIALOGUE:     15882        1  \n",
       "1600       PERSONS OF THE DIALOGUE:     22251        1  \n",
       "1616       PERSONS OF THE DIALOGUE:     23939        1  \n",
       "1635       PERSONS OF THE DIALOGUE:      5178        1  \n",
       "1636       PERSONS OF THE DIALOGUE:     23210        1  \n",
       "1642       PERSONS OF THE DIALOGUE:      6793        1  \n",
       "1643       PERSONS OF THE DIALOGUE:     12855        1  \n",
       "1656                        APOLOGY     11406        1  \n",
       "1657       PERSONS OF THE DIALOGUE:      5389        1  \n",
       "1658       PERSONS OF THE DIALOGUE:     27512        1  \n",
       "1672       PERSONS OF THE DIALOGUE:     35833        1  \n",
       "1673       PERSONS OF THE DIALOGUE:      6048        1  \n",
       "1676       PERSONS OF THE DIALOGUE:     14811        1  \n",
       "1677       PERSONS OF THE DIALOGUE:      5531        1  \n",
       "1681       PERSONS OF THE DIALOGUE:      6419        1  \n",
       "1682       PERSONS OF THE DIALOGUE:      6581        1  \n",
       "1687       PERSONS OF THE DIALOGUE:     18974        1  \n",
       "1726       PERSONS OF THE DIALOGUE:     31453        1  \n",
       "1735       PERSONS OF THE DIALOGUE:     22230        1  \n",
       "1738       PERSONS OF THE DIALOGUE:     23617        1  \n",
       "1744       PERSONS OF THE DIALOGUE:     23398        1  \n",
       "1750     ^\\s*BOOK\\s+[IVXLCM]+\\.\\s*$    141143       12  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB['book_len'] = CORPUS.groupby('book_id').term_str.count()\n",
    "LIB['n_chaps'] = CORPUS.reset_index()[['book_id','chap_id']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_id').chap_id.count()\n",
    "LIB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a822bce",
   "metadata": {},
   "source": [
    "Extracting a vocab table with annotations for the stopwords and stemming - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "92c88af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zones</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zopyrus</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoroaster</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zosin</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zugon</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17140 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            n  stop\n",
       "term_str           \n",
       "           95     0\n",
       "1          38     0\n",
       "10          1     0\n",
       "100        13     0\n",
       "10000       1     0\n",
       "...        ..   ...\n",
       "zones       9     0\n",
       "zopyrus     1     0\n",
       "zoroaster   1     0\n",
       "zosin       1     0\n",
       "zugon       3     0\n",
       "\n",
       "[17140 rows x 2 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n').sort_index()\n",
    "VOCAB.index.name = 'term_str'\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b21a4e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zones</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>zone</td>\n",
       "      <td>zone</td>\n",
       "      <td>zon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zopyrus</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>zopyru</td>\n",
       "      <td>zopyrus</td>\n",
       "      <td>zopyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoroaster</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>zoroast</td>\n",
       "      <td>zoroast</td>\n",
       "      <td>zoroast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zosin</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>zosin</td>\n",
       "      <td>zosin</td>\n",
       "      <td>zosin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zugon</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>zugon</td>\n",
       "      <td>zugon</td>\n",
       "      <td>zugon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17140 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            n  stop stem_porter stem_snowball stem_lancaster\n",
       "term_str                                                    \n",
       "           95     0                                         \n",
       "1          38     0           1             1              1\n",
       "10          1     0          10            10             10\n",
       "100        13     0         100           100            100\n",
       "10000       1     0       10000         10000          10000\n",
       "...        ..   ...         ...           ...            ...\n",
       "zones       9     0        zone          zone            zon\n",
       "zopyrus     1     0      zopyru       zopyrus          zopyr\n",
       "zoroaster   1     0     zoroast       zoroast        zoroast\n",
       "zosin       1     0       zosin         zosin          zosin\n",
       "zugon       3     0       zugon         zugon          zugon\n",
       "\n",
       "[17140 rows x 5 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.apply(lambda x: stemmer2.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.apply(lambda x: stemmer3.stem(x.name), 1)\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b1da4",
   "metadata": {},
   "source": [
    "Applying the gather function to make a document table at the sentence level - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d3d92d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1497</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>I went down yesterday to the Piraeus with Glau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>); and also because I wanted to see in what ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was delighted with the procession of the inh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When we had finished our prayers and viewed th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The servant took hold of me by the cloak behin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1750</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">12</th>\n",
       "      <th>121</th>\n",
       "      <th>3</th>\n",
       "      <td>And the state will be perfected and become a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>0</th>\n",
       "      <td>MEGILLUS: Dear Cleinias, after all that has be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <th>0</th>\n",
       "      <td>CLEINIAS: Very true, Megillus; and you must jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <th>0</th>\n",
       "      <td>MEGILLUS: I will.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <th>0</th>\n",
       "      <td>End of the Project Gutenberg EBook of Laws, by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31091 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            sent_str\n",
       "book_id chap_id para_num sent_num                                                   \n",
       "1497    1       1        0         I went down yesterday to the Piraeus with Glau...\n",
       "                         1         ); and also because I wanted to see in what ma...\n",
       "                         2         I was delighted with the procession of the inh...\n",
       "                         3         When we had finished our prayers and viewed th...\n",
       "                         4         The servant took hold of me by the cloak behin...\n",
       "...                                                                              ...\n",
       "1750    12      121      3         And the state will be perfected and become a w...\n",
       "                122      0         MEGILLUS: Dear Cleinias, after all that has be...\n",
       "                123      0         CLEINIAS: Very true, Megillus; and you must jo...\n",
       "                124      0                                         MEGILLUS: I will.\n",
       "                127      0         End of the Project Gutenberg EBook of Laws, by...\n",
       "\n",
       "[31091 rows x 1 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC = gather(CORPUS, 4)\n",
    "DOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a737c6",
   "metadata": {},
   "source": [
    "Outputting all the tables as csvs - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8a842006",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.to_csv(f'{out_path}-LIB.csv')\n",
    "VOCAB.to_csv(f'{out_path}-VOCAB.csv')\n",
    "CORPUS.to_csv(f'{out_path}-CORPUS.csv')\n",
    "DOC.to_csv(f'{out_path}-DOC.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
